{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chain\n",
    "\n",
    "## Review\n",
    "\n",
    "We built a simple graph with nodes, normal edges, and conditional edges.\n",
    "\n",
    "## Goals\n",
    "\n",
    "Now, let's build up to a simple chain that combines 4 [concepts](https://python.langchain.com/v0.2/docs/concepts/):\n",
    "\n",
    "* Using [chat messages](https://python.langchain.com/v0.2/docs/concepts/#messages) as our graph state\n",
    "* Using [chat models](https://python.langchain.com/v0.2/docs/concepts/#chat-models) in graph nodes\n",
    "* [Binding tools](https://python.langchain.com/v0.2/docs/concepts/#tools) to our chat model\n",
    "* [Executing tool calls](https://python.langchain.com/v0.2/docs/concepts/#functiontool-calling) in graph nodes \n",
    "\n",
    "![Screenshot 2024-08-21 at 9.24.03 AM.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbab08dd607b08df5e1101_chain1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Messages\n",
    "\n",
    "Chat models can use [`messages`](https://python.langchain.com/v0.2/docs/concepts/#messages), which capture different roles within a conversation. \n",
    "\n",
    "LangChain supports various message types, including `HumanMessage`, `AIMessage`, `SystemMessage`, and `ToolMessage`. \n",
    "\n",
    "These represent a message from the user, from chat model, for the chat model to instruct behavior, and from a tool call. \n",
    "\n",
    "Let's create a list of messages. \n",
    "\n",
    "Each message can be supplied with a few things:\n",
    "\n",
    "* `content` - content of the message\n",
    "* `name` - optionally, a message author \n",
    "* `response_metadata` - optionally, a dict of metadata (e.g., often populated by model provider for `AIMessages`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from langchain_core.messages import AIMessage, HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [HumanMessage(content=\"Hi my name is Soutrik\", name=\"User\")]\n",
    "messages.append(AIMessage(content=\"Hi Soutrik, nice to meet you!\", name=\"Assistant\"))\n",
    "messages.append(HumanMessage(content=\"Can you please give me some details about mount Abu ?\", name=\"User\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: User\n",
      "\n",
      "Hi my name is Soutrik\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: Assistant\n",
      "\n",
      "Hi Soutrik, nice to meet you!\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: User\n",
      "\n",
      "Can you please give me some details about mount Abu ?\n"
     ]
    }
   ],
   "source": [
    "for m in messages:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat Models\n",
    "\n",
    "[Chat models](https://python.langchain.com/v0.2/docs/concepts/#chat-models) can use a sequence of message as input and support message types, as discussed above.\n",
    "\n",
    "There are [many](https://python.langchain.com/v0.2/docs/concepts/#chat-models) to choose from! Let's work with OpenAI. \n",
    "\n",
    "Let's check that your `OPENAI_API_KEY` is set and, if not, you will be asked to enter it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "result = llm.invoke(messages)\n",
    "type(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Mount Abu is a popular hill station located in the Aravalli Range in the state of Rajasthan, India. Here are some key details about Mount Abu:\\n\\n1. **Location**: It is situated in the Sirohi district of Rajasthan, close to the Gujarat border, and is the only hill station in Rajasthan.\\n\\n2. **Climate**: The climate is relatively cool compared to the surrounding desert regions, with temperatures ranging from pleasant to moderately warm. The summer season is from April to June, monsoon from July to September, and winter from November to February.\\n\\n3. **Tourist Attractions**:\\n   - **Dilwara Temples**: Famous for their stunning marble architecture and intricate carvings, these Jain temples are a major attraction.\\n   - **Nakki Lake**: A picturesque lake surrounded by hills and forests, ideal for boating and picnics.\\n   - **Guru Shikhar**: The highest peak in the Aravalli Range, offering panoramic views of the surrounding area.\\n   - **Achalgarh Fort**: A historical fort with ancient temples, offering both historical insight and scenic views.\\n   - **Mount Abu Wildlife Sanctuary**: Home to a variety of flora and fauna, this sanctuary offers a great opportunity for nature enthusiasts.\\n\\n4. **Cultural Significance**: Mount Abu has a rich cultural heritage, with numerous ancient temples and monuments. It is a significant place for Jain pilgrims due to the Dilwara Temples.\\n\\n5. **Adventure Activities**: The region offers various activities like trekking, rock climbing, and camping, making it popular among adventure seekers.\\n\\n6. **How to Reach**:\\n   - **By Air**: The nearest airport is in Udaipur, about 185 km away.\\n   - **By Train**: The nearest railway station is Abu Road, approximately 28 km from Mount Abu.\\n   - **By Road**: Well-connected by road, with buses and taxis available from major cities in Rajasthan and Gujarat.\\n\\nIf you're planning a visit, the best time would be during the cooler months from November to March.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 420, 'prompt_tokens': 49, 'total_tokens': 469, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_07871e2ad8', 'id': 'chatcmpl-Bf6dlk0qKEK6cVxdBLmVhIFQXCgy0', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--0ee7a173-a4ab-4fbc-a8d3-37ecdb353c8b-0' usage_metadata={'input_tokens': 49, 'output_tokens': 420, 'total_tokens': 469, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "{'input_tokens': 49, 'output_tokens': 420, 'total_tokens': 469, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "{'token_usage': {'completion_tokens': 420, 'prompt_tokens': 49, 'total_tokens': 469, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_07871e2ad8', 'id': 'chatcmpl-Bf6dlk0qKEK6cVxdBLmVhIFQXCgy0', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}\n"
     ]
    }
   ],
   "source": [
    "print(result)\n",
    "print(result.usage_metadata)\n",
    "print(result.response_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools\n",
    "\n",
    "Tools are useful whenever you want a model to interact with external systems.\n",
    "\n",
    "External systems (e.g., APIs) often require a particular input schema or payload, rather than natural language. \n",
    "\n",
    "When we bind an API, for example, as a tool we given the model awareness of the required input schema.\n",
    "\n",
    "The model will choose to call a tool based upon the natural language input from the user. \n",
    "\n",
    "And, it will return an output that adheres to the tool's schema. \n",
    "\n",
    "[Many LLM providers support tool calling](https://python.langchain.com/v0.1/docs/integrations/chat/) and [tool calling interface](https://blog.langchain.dev/improving-core-tool-interfaces-and-docs-in-langchain/) in LangChain is simple. \n",
    " \n",
    "You can simply pass any Python `function` into `ChatModel.bind_tools(function)`.\n",
    "\n",
    "![Screenshot 2024-08-19 at 7.46.28 PM.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbab08dc1c17a7a57f9960_chain2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "llm_with_tools = llm.bind_tools([multiply])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we pass an input - e.g., `\"What is 2 multiplied by 3\"` - we see a tool call returned. \n",
    "\n",
    "The tool call has specific arguments that match the input schema of our function along with the name of the function to call.\n",
    "\n",
    "```\n",
    "{'arguments': '{\"a\":2,\"b\":3}', 'name': 'multiply'}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_call = llm_with_tools.invoke([HumanMessage(content=f\"What is 2 multiplied by 3\", name=\"Lance\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'multiply',\n",
       "  'args': {'a': 2, 'b': 3},\n",
       "  'id': 'call_ero6sT41Pig4GUKIE0Zs5Wcv',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_call.tool_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using messages as state\n",
    "\n",
    "With these foundations in place, we can now use [`messages`](https://python.langchain.com/v0.2/docs/concepts/#messages) in our graph state.\n",
    "\n",
    "Let's define our state, `MessagesState`, as a `TypedDict` with a single key: `messages`.\n",
    "\n",
    "`messages` is simply a list of messages, as we defined above (e.g., `HumanMessage`, etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from langchain_core.messages import AnyMessage\n",
    "\n",
    "\n",
    "class MessagesState(TypedDict):\n",
    "    messages: list[AnyMessage]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reducers\n",
    "\n",
    "Now, we have a minor problem! \n",
    "\n",
    "As we discussed, each node will return a new value for our state key `messages`.\n",
    "\n",
    "But, this new value [will override](https://langchain-ai.github.io/langgraph/concepts/low_level/#reducers) the prior `messages` value.\n",
    " \n",
    "As our graph runs, we want to **append** messages to our `messages` state key.\n",
    " \n",
    "We can use [reducer functions](https://langchain-ai.github.io/langgraph/concepts/low_level/#reducers) to address this.\n",
    "\n",
    "Reducers allow us to specify how state updates are performed.\n",
    "\n",
    "If no reducer function is specified, then it is assumed that updates to the key should *override it* as we saw before.\n",
    " \n",
    "But, to append messages, we can use the pre-built `add_messages` reducer.\n",
    "\n",
    "This ensures that any messages are appended to the existing list of messages.\n",
    "\n",
    "We simply need to annotate our `messages` key with the `add_messages` reducer function as metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.graph import MessagesState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conventionally we would use a TypedDict to define the state of the graph\n",
    "class MessagesState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same as above but with a different approach\n",
    "class MessagesState(MessagesState):\n",
    "    # Add any keys needed beyond messages, which is pre-built\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='Hello! How can I assist you?', additional_kwargs={}, response_metadata={}, name='Model', id='fb5670f6-7a66-429d-a6d7-4dde4eb4546d'),\n",
       " HumanMessage(content=\"I'm looking for information on marine biology.\", additional_kwargs={}, response_metadata={}, name='Lance', id='9ba958a7-98ad-4514-b2e8-b2f4f33b5f2e'),\n",
       " AIMessage(content='Sure, I can help with that. What specifically are you interested in?', additional_kwargs={}, response_metadata={}, name='Model', id='5fcfa95d-ac5a-43a3-8225-e8e04214cdf9')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initial state\n",
    "initial_messages = [\n",
    "    AIMessage(content=\"Hello! How can I assist you?\", name=\"Model\"),\n",
    "    HumanMessage(content=\"I'm looking for information on marine biology.\", name=\"Lance\"),\n",
    "]\n",
    "\n",
    "# New message to add\n",
    "new_message = AIMessage(content=\"Sure, I can help with that. What specifically are you interested in?\", name=\"Model\")\n",
    "\n",
    "# Test\n",
    "add_messages(initial_messages, new_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our graph\n",
    "\n",
    "Now, lets use `MessagesState` with a graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from langgraph.graph import StateGraph, START, END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MessagesState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tool_call(state: MessagesState):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build graph\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"tool_calling_llm\", tool_call)\n",
    "builder.add_edge(START, \"tool_calling_llm\")\n",
    "builder.add_edge(\"tool_calling_llm\", END)\n",
    "graph = builder.compile()\n",
    "\n",
    "# View\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hello!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "messages = graph.invoke({\"messages\": HumanMessage(content=\"Hello!\")})\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Multiply 2 and 3\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (call_ED51q9BMQQKzN6Nop6dUjAmp)\n",
      " Call ID: call_ED51q9BMQQKzN6Nop6dUjAmp\n",
      "  Args:\n",
      "    a: 2\n",
      "    b: 3\n"
     ]
    }
   ],
   "source": [
    "messages = graph.invoke({\"messages\": HumanMessage(content=\"Multiply 2 and 3\")})\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
